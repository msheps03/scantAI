{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train CNN on 'ImageNet' -> Remove classification layer -> make predictions on training set with CNN -> Output of this prediction is the extracted feature.\n",
    "\n",
    "Extracted Features + Labels -> Train Gaussian Mixture Model (GMM) -> Predict on Test set of 'ImageNet' images "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes:\n",
    "69: Trilobite\n",
    "70: Daddy Longleg\n",
    "71: Scorpion\n",
    "72: Black & Gold Spider\n",
    "73: Barn Spider\n",
    "74: Garden Spider\n",
    "75: Black Widow\n",
    "76: Tarantula\n",
    "77: Wolf Spider\n",
    "78: Tick\n",
    "79: Centipede"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & Format Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car images from natural images\n",
    "train_img_dir_n = \"../OneClass/Ticks_2D/train\"\n",
    "train_img_paths_n = [join(train_img_dir_n,filename) for filename in os.listdir(train_img_dir_n)]\n",
    "\n",
    "# import car images from stanford cars\n",
    "train_img_dir_s = \"../OneClass/Other/Tick\"\n",
    "all_train_img_paths_s = [join(train_img_dir_s,filename) for filename in os.listdir(train_img_dir_s)]\n",
    "\n",
    "# split cars data into train, test, and val\n",
    "train_img_paths, test_img_paths_car = train_test_split(all_train_img_paths_s+train_img_paths_n, test_size=0.25, random_state=42)\n",
    "train_img_paths, val_img_paths_car = train_test_split(train_img_paths, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import ~car images\n",
    "natural_images_path = \"../OneClass/Other/\"\n",
    "test_img_paths_no_car = []\n",
    "for d in [d for d in os.listdir(\"../OneClass/Other\") if d!= \"Tick\"]:\n",
    "    test_img_dir_na = natural_images_path+d\n",
    "    test_img_paths_no_car.append([join(test_img_dir_na,filename) for filename in os.listdir(test_img_dir_na)])\n",
    "    \n",
    "test_img_paths_no_car_flat = [item for sublist in test_img_paths_no_car for item in sublist]\n",
    "test_img_paths_no_car, val_img_paths_no_car = train_test_split(test_img_paths_no_car_flat, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_img_dir(image_path):\n",
    "    path_regex = r\"Other\\/(\\w*)\"\n",
    "    if 'natural_images' in image_path:\n",
    "        return re.findall(path_regex,image_path,re.MULTILINE)[0].strip()\n",
    "    else:\n",
    "        return 'car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataframe\n",
    "all_test_paths = test_img_paths_car+test_img_paths_no_car\n",
    "test_path_df = pd.DataFrame({\n",
    "    'path': all_test_paths,\n",
    "    'is_car': [1 if path in test_img_paths_car else 0 for path in all_test_paths]\n",
    "})\n",
    "test_path_df = shuffle(test_path_df,random_state = 0).reset_index(drop = True)\n",
    "test_path_df['image_type'] = test_path_df['path'].apply(lambda x: natural_img_dir(x))\n",
    "all_test_paths = test_path_df['path'].tolist()\n",
    "\n",
    "print('Distribution of Image Types in Test Set')\n",
    "print(test_path_df['image_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create val dataframe\n",
    "all_val_paths = val_img_paths_car+val_img_paths_no_car\n",
    "val_path_df = pd.DataFrame({\n",
    "    'path': all_val_paths,\n",
    "    'is_car': [1 if path in val_img_paths_car else 0 for path in all_val_paths]\n",
    "})\n",
    "val_path_df = shuffle(val_path_df,random_state = 0).reset_index(drop = True)\n",
    "val_path_df['image_type'] = val_path_df['path'].apply(lambda x: natural_img_dir(x))\n",
    "all_val_paths = val_path_df['path'].tolist()\n",
    "\n",
    "print('Distribution of Image Types in Validation Set')\n",
    "print(val_path_df['image_type'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction With ResNet50\n",
    "Removing the prediction layer of the pretrained Resnet50 model allows features to quickly be extracted from selected images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare images for resnet50\n",
    "image_size = 150\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    #output = img_array\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "X_train = read_and_prep_images(train_img_paths)\n",
    "X_test = read_and_prep_images(all_test_paths)\n",
    "X_val = read_and_prep_images(all_val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 25s 320ms/step\n",
      "339/339 [==============================] - 110s 324ms/step\n",
      "127/127 [==============================] - 41s 323ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model\n",
    "# get features from resnet50 \n",
    "\n",
    "#resnet_weights_path = '../OneClass/Models/augmented_resnet50-saved-model-14-val_acc-0.28.hdf5'\n",
    "resnet_weights_path = 'imagenet'\n",
    "# X : images numpy array\n",
    "resnet_model = ResNet50(input_shape=(image_size, image_size, 3), weights=resnet_weights_path, include_top=False, pooling='avg')  # Since top layer is the fc layer used for predictions\n",
    "\n",
    "\n",
    "\n",
    "X_train = resnet_model.predict(X_train)\n",
    "X_test = resnet_model.predict(X_test)\n",
    "X_val = resnet_model.predict(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA scaling\n",
    "Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaler to output from resnet50\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "X_val = ss.transform(X_val)\n",
    "\n",
    "# Take PCA to reduce feature space dimensionality\n",
    "pca = PCA(n_components=512, whiten=True)\n",
    "pca = pca.fit(X_train)\n",
    "print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val_path_df['is_car'].tolist()\n",
    "\n",
    "gmm_clf = GaussianMixture(covariance_type='spherical', n_components=18, max_iter=int(1e7))  # From Article (These params should be optimized for this problem)\n",
    "gmm_clf.fit(X_train)\n",
    "log_probs_val = gmm_clf.score_samples(X_val)\n",
    "isotonic_regressor = IsotonicRegression(out_of_bounds='clip')\n",
    "isotonic_regressor.fit(log_probs_val, y_val)  # y_val is for labels 0 - not car 1 - car (validation set)\n",
    "\n",
    "# Obtaining results on the test set\n",
    "log_probs_test = gmm_clf.score_samples(X_test)\n",
    "test_probabilities = isotonic_regressor.predict(log_probs_test)\n",
    "test_predictions = [1 if prob >= 0.5 else 0 for prob in test_probabilities]\n",
    "\n",
    "gmm_results = pd.DataFrame({\n",
    "  'path': all_test_paths,\n",
    "  'gmm_preds': test_predictions\n",
    "})\n",
    "\n",
    "gmm_results = gmm_results.merge(test_path_df)\n",
    "gmm_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('roc auc score: gmm_preds')\n",
    "gmm_preds = gmm_results['gmm_preds']\n",
    "actual = gmm_results['is_car']\n",
    "print(roc_auc_score(actual, gmm_preds))\n",
    "print(classification_report(actual, gmm_preds))\n",
    "sns.heatmap(confusion_matrix(actual, gmm_preds),annot = True,fmt = '2.0f')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
